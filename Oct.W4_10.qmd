---
title: "Oct.W3_3rd"
format: html
editor: visual
---

## W4_1st

```{r}

library(here)

rm(list=ls())

raw_moon <- readLines(here("data", "speech_moon.txt"), encoding = "UTF-8")
head(raw_moon)

#str_repalce_all, remove unnecessary words

txt <- "치킨은!! 맛있따. xyz 정말 맛있따!@#"
txt

install.packages("stringr")
library(stringr)
str_replace_all(string = txt, pattern = "[가-힣]", replacement = " ")

moon <- raw_moon %>% 
  str_replace("[^가-힣]", " ")
head(moon)

?str_replace_all

txt <- "치킨은   맛있다   정말 맛있다"
txt
str_squish(txt)

moon <- moon %>% 
  str_squish()
head(moon)

# change characgteristic vetor into tibble  

library(dplyr)

moon <- as_tibble(moon)
moon

moon <- raw_moon %>% 
  str_replace_all("[^가-힣]", " ") %>% 
  str_squish() %>% 
  as_tibble()

#tibble vs. data frame
iris
as_tibble(iris)
```

## Sept. 30th

-   Unnest_tokens\_\_tidytext
-   Word frequency analysis_count()

```{r}
text <- tibble(value = "The republic of korea is a democratic republic. The sovereignty of the republic of korea resides in the people, and all authority comes from the people.")
text

require("tidytext")
text %>% 
  unnest_tokens(input = value, #text to be tokend
                output = word, #input name of variable
                token = "sentences") # by sentence

text %>% 
  unnest_tokens(input = value, #text to be tokend
                output = word, #input name of variable
                token = "words") # by space

text %>% 
  unnest_tokens(input = value,
                output = word,
                token = "characters")

word_space <- moon %>% 
  unnest_tokens(input = value,
                output = word,
                token = "words")
word_space


word_space <- word_space %>% 
  count(word, sort = T)
word_space

#remove one-letter words _ stringr -- str_count()
str_count("배")
str_count("사과")

# leave at least two charaters

word_space <- word_space %>% 
  filter(str_count(word) > 1)

word_space

# code all at once

word_space <- moon %>% 
  unnest_tokens(input = value,
                output = word,
                token = "words")

word_space <- word_space %>% 
  count(word, sort = T) %>% 
  filter(str_count(word) > 1)

word_space

# Extracting high grequency words

top20 <- word_space %>% 
  head(20)

top20

library(ggplot2)
ggplot(top20, aes(x = reorder(word, n), y = n)) +
  geom_col() +
coord_flip()

#trimming graph
ggplot(top20, aes(x = reorder(word, n), y =n)) +
  geom_col() +
  coord_flip () +
  geom_text(aes(label = n), hjust = -0.3) +
  labs(title = "Word frequency of Moon Jae-in's candidacy speech", 
       x = NULL, y = NULL) + #delet axix name
  theme(title = element_text(size = 12)) #title size

#making word cloud _ geom_text_wordcloud()
require("ggwordcloud")

ggplot(word_space, aes(label = word, siz = n)) +
  geom_text_wordcloud(seed = 1234) + 
  scale_radius(limits = c(3, NA), #frequency word size
               range = c(3, 30)) #size of words


#trimming grpah_scale_color_gradient()
ggplot(word_space,
       aes(label = word,
           size = n,
           col = n)) +
  geom_text_wordcloud(seed = 1234) + 
  scale_radius(limits = c(3, NA),
               range = c(3, 30)) +
  scale_color_gradient(low = "#66aaf2",
                       high = "#004EA1") +
  theme_minimal()




```

## Oct. 1st

-   change graph's font\
    showtext\
    font_add_google()

```{r}
install.packages("showtext")
library(showtext)

font_add_google(name = "Nanum Gothic", family = "nanugothic")
showtext_auto()

#specifying a font in a graph
library(ggplot2)
library(ggwordcloud)

ggplot(word_space,
       aes(label = word,
           size = n,
           col = n )) +
  geom_text_wordcloud(seed = 1234,
                      family = "nanumgotghic") +
  scale_radius(limits = c(3, NA),
               range = c(3, 30)) +
  scale_color_gradient(low = "#66aaf2",
                       high = "#004EA1") +
  theme_minimal()


font_add_google(name = "Black han Sans", family = "blackhansans")
showtext_auto()

ggplot(word_space, aes(label = word,
                       size = n,
                       col = n)) +
  geom_text_wordcloud(seed = 1234,
                      family = "blackhansans") +
  scale_radius(limits = c(3, NA),
               range = c(3, 30)) +
  scale_color_gradient(low = "#66aaf2",
                       high = "#004EA1") +
  theme_minimal()

#change font 

font_add_google(name = "Gamja Flower", family = "gamjaflower")
showtext_auto()

ggplot(top20, aes(x = reorder(word, n), y = n)) +
  geom_col() +
  coord_flip() +
  geom_text(aes(label = n), hjust = -0.3) +
  labs(title = "문재인 대통령 출마 선언문 단어 빈도",
       x = NULL, y = NULL) +
  theme(title = element_text(size = 12), 
        text = element_text(family = "gamjaflower"))
```

## Oct. 3rd

-   practice

```{r}
library(here)
library(stringr)
library(dplyr)
library(tidytext)
library(ggplot2)
library(ggwordcloud)

raw_park <- readLines(here("data", "speech_park.txt"), encoding = "UTF-8")
park <- raw_park %>% 
  str_replace_all("[^가-힣]", " ") %>% 
  str_squish() %>% 
  as_tibble()

# check out the name of column
head(park)

park_word <- park %>% 
  unnest_tokens(input = value,
                output = word,
                token = "words") %>% 
  filter(str_count(word) > 1) %>% 
  count(word, sort = T)


park_word_20 <- head(park_word, 20)

ggplot(data = park_word_20, aes(x = reorder(word, n), y = n )) +
  geom_col() +
  coord_flip()


ggplot(park_word_20, aes(label = word, size = n)) + 
  geom_text_wordcloud(seed = 0512) + 
  scale_radius(limits = c(3, NA),
                range = c(3, 30))
```

## Oct. 4th

-   morphological analysis

    ```{r}
    install.packages("multilinguer")
    library(multilinguer)
    install_jdk

    install.packages(c("stringr", "hash", "tau", "Sejong", "RSQLite", "devtools"),
                     type = "binary")

    #3 Install Package of KoNLP
    install.packages("remotes")
    remotes::install_github("haven-jeon/KoNLP",
                            upgrade = "never",
                            INSTALL_opts = c("--no-multiarch"), 
                            force = TRUE)

    library(KoNLP)

    useNIADic()


    #extractNoun -- KoNLP
    library(KoNLP)
    library(dplyr)
    text <- tibble(
      value = c("대한민국은 민주공화국이다.",
                "대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.")
    )
    extractNoun(text$value)


    ###
    # Unload the KoNLP package
    detach("package:KoNLP", unload = TRUE)

    # Restart R session to ensure all dependencies are unloaded
    .rs.restartR()

    # Reinstall KoNLP from GitHub
    remotes::install_github('haven-jeon/KoNLP', upgrade = "never", force = TRUE)

    Sys.setenv(JAVA_HOME = "C:/Program Files/Java/jdk-11.0.10")

    # Install MeCab using KoNLP (may require administrator privileges)
    KoNLP::install_mecab("C:/mecab")

    # Load the KoNLP package
    library(KoNLP)

    # Use the Sejong dictionary
    useSejongDic()


    # Ensure the 'here' package is installed and loaded
    library(here)

    # Correctly read the file
    raw_moon <- readLines(here("Data", "speech_moon.txt"), encoding = "UTF-8")
    Sys.getenv("JAVA_HOME")
    Sys.setenv(JAVA_HOME = "C:/Program Files/Java/jdk-11.0.10")
    remove.packages("rJava")
    install.packages("rJava")
    library(rJava)
    .jinit()


    remotes::install_github('haven-jeon/KoNLP', upgrade = "never", force = TRUE)

    Sys.getenv("JAVA_HOME")
    Sys.setenv(JAVA_HOME = "C:/Program Files/Amazon Corretto/jdk11.0.20_9")
    remove.packages("rJava")
    install.packages("rJava")
    library(rJava)
    .jinit()
    remove.packages("KoNLP")
    install.packages("remotes")

    remotes::install_github('haven-jeon/KoNLP', upgrade = "never")

    options(download.file.method = "libcurl")

    remotes::install_github('haven-jeon/KoNLP', upgrade = "never", force = TRUE)

    library(KoNLP)
    useSejongDic()
    extractNoun("대한민국의 주권은 국민에게 있다.")


    options(download.file.method = "libcurl")
    install.packages("remotes")
    library(remotes)
    remotes::install_github('haven-jeon/KoNLP', upgrade = "never", force = TRUE)

    library(KoNLP)
    useSejongDic()
    extractNoun("한국어 형태소 분석을 테스트합니다.")
    ```

## Oct. 8th

```{r}
Sys.setenv(JAVA_HOME = "C:/Program Files/Java/jdk1.8.0_202")
Sys.getenv("JAVA_HOME")

library(multilinguer)

remotes::install_github("haven-jeon/KoNLP", lib = "C:/R/library", upgrade = "never", INSTALL_opts = c("--no-multiarch"), force = TRUE)

library(KoNLP)
library(dplyr)
text <- tibble(
  value = c("대한민국은 민주공화국이다.", 
            "대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.")
)

text
extractNoun(text$value)

library(tidytext)

text %>% 
  unnest_tokens(input = value,
               output = word, 
               token = extractNoun)

library(here)
raw_moon <- readLines(here("Data", "speech_moon.txt"), encoding = "UTF-8")

library(stringr)
install.packages("textclean")
library(textclean)

moon <- raw_moon %>% 
  str_replace_all("[^가-힣]", " ") %>% 
  str_squish() %>% 
  as_tibble()

word_noun <- moon %>% 
  unnest_tokens(input = value,
                output = word,
                token = extractNoun)

word_noun <- word_noun %>% 
  count(word, sort = T) %>% 
  filter(str_count(word) >1 )

word_noun
```

## Oct. 9th

```{r}
top20 <- word_noun %>% 
  head(20)

library(ggplot2)
ggplot(top20, aes(x = reorder(word, n), y = n)) +
  geom_col() +
coord_flip() +
  geom_text(aes(label = n), hjust = -0.3) +
  labs(x = NULL) +
  theme(text = element_text(family = "nanumgothic"))

library(showtext)
font_add_google(name = "Black Han Sans", family = "blackhansans")
showtext_auto()

library(ggwordcloud)
ggplot(word_noun, aes(label = word, size = n, col = n)) +
  geom_text_wordcloud(seed = 1234, family = "blackhansans") +
  scale_radius(limits = c(3, NA), 
               range = c(3, 15)) +
  scale_color_gradient(low = "#66aaf2", high = '#004EA1') +
  theme_minimal()


```

## Oct. 10th

-   Extract a sentence containing specific words_str_detect()

```{r}

library(tidytext)
library(dplyr)

sentences_moon <- raw_moon %>% 
  str_squish() %>% 
  as_tibble() %>% 
  unnest_tokens(input = value,
                output = sentence,
                token = "sentences")

sentences_moon

library(stringr)
str_detect("치킨은 맛있다", "치킨")
str_detect("치킨은 맛있다", "피자")

sentences_moon %>% 
  filter(str_detect(sentence, "국민"))

sentences_moon %>% 
  filter(str_detect(sentence, "일자리"))

```
